

\begin{flushleft}
~\cite{campos2022singularity} Singularity of Random Symmetric Matrices: This paper studies the probability, denoted as ${P(det(M_n) = 0)}$, of a singular random ${n \times n}$ matrix ${M_n}$ drawn uniformly from matrices with entries of ${-1}$ and ${1}$. It's a long-standing problem with the conjecture that ${P(det(M_n) = 0)}$ goes to zero exponentially fast with ${n}$, written as ${P(det(M_n) = 0) = (1 + o(1))n^{2}2^{-n+1}}$. Prior work established bounds on this probability but couldn't overcome a natural barrier of ${exp(-c\sqrt{n} log n)}$ for some constant ${c}$, where the randomness in the matrix isn't "reused."\\
This paper breaks the barrier by introducing a "rough" inverse Littlewood-Offord theorem, proving that\ ${P(det(M_n) = 0) \leq exp(-cpn log n)}$ for some constant ${c}$ and sufficiently large ${n}$. The authors build upon previous work that divides vectors ${v}$ into structured and unstructured and analyzes their contribution to ${P(det(M_n) = 0)}$. Their key improvement lies in a simpler and stronger "rough" inverse Littlewood-Offord theorem, which defines concepts like ${N_{\mu}(w) := {x \in \mathbb{Z}_{p} : P(X \mu (w) = x) > 2^{-1}P(X_{\mu}(w) = 0)}}$ to analyze the "neighborhood" of a vector ${w}$ under a random walk ${X_{\mu}(v) := \varepsilon_1 v_1 + ... + \varepsilon_n v_n}$, where ${\varepsilon_i}$ are independent and take values ${-1}$, ${0}$, or ${1}$ with equal probability ${\mu /2}$.
\end{flushleft} 